# -*- coding: utf-8 -*-
"""Lr_3_task_5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ivwT6FNpjCMub4JUHC1yixqVIY78s_ox
"""

import matplotlib.pyplot as plt
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import mean_squared_error, r2_score

# Generate random data
np.random.seed(42)
m = 100
X = np.linspace(-3, 3, m)
y = np.sin(X) + np.random.uniform(-0.5, 0.5, m)

# Reshape X to a column vector
X = X.reshape(-1, 1)

# Plot the original data
plt.scatter(X, y, label='Original Data')

# Linear regression
linear_regressor = LinearRegression()
linear_regressor.fit(X, y)
y_linear_pred = linear_regressor.predict(X)
plt.plot(X, y_linear_pred, label='Linear Regression', color='red')

# Polynomial regression
degree = 3  # You can adjust the degree of the polynomial
poly_features = PolynomialFeatures(degree=2, include_bias=False)
X_poly = poly_features.fit_transform(X)
poly_regressor = LinearRegression()
poly_regressor.fit(X_poly, y)
print("Linear Term (X[0]) coefficient:", poly_regressor.coef_[1])
print("Polynomial Features (X_poly) coefficients:", poly_regressor.coef_[2:])
# Fit LinearRegression to the extended training data
lin_reg = LinearRegression()
lin_reg.fit(X_poly, y)

# Print the intercept and coefficients
print("Intercept:", lin_reg.intercept_)
print("Coefficients:", lin_reg.coef_)

y_poly_pred = poly_regressor.predict(X_poly)
plt.plot(X, y_poly_pred, label='Polynomial Regression', color='green')

# Evaluate models
print("Linear Regression - R2 Score:", r2_score(y, y_linear_pred))
print("Polynomial Regression - R2 Score:", r2_score(y, y_poly_pred))

# Display the plot
plt.legend()
plt.title('Linear and Polynomial Regression')
plt.xlabel('X')
plt.ylabel('y')
plt.show()